{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.sparse import diags\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import sys\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing seaborn for plotting\n",
    "import seaborn as sns\n",
    "\n",
    "#for plotting purposes\n",
    "%pylab inline\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['figure.figsize'] = [8, 16/3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for use in processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#porting from HITRACE\n",
    "#based on Baseline correction for NMR spectroscopic metabolomics data analysis. 2008, \n",
    "#Author(s): Xi, Yuanxin and Rocke, David M\n",
    "#https://doi.org/10.1186/1471-2105-9-324 and further modified by Rhiju (Stanford University)\n",
    "#name of variables tracks closely to what is presented in the manuscript\n",
    "\n",
    "def baseline_xi(b,A=2e9,B=2e4,s=1.0):\n",
    "    # Input: \n",
    "    # b Nx1, spectrum data\n",
    "    # A 1x1 smoothing factor\n",
    "    # B 1x1 negative penalty\n",
    "    # s 1x1 noise standard deviation\n",
    "\n",
    "    # Output:\n",
    "    # bd Nx1 baseline\n",
    "    # b_subtract Nx1 background subtracted trace\n",
    "\n",
    "    L = len(b)\n",
    "\n",
    "    # b is the SIGNAL (gamma in the paper). bd is the estimated baseline (b in the paper).\n",
    "    bd = np.ones((L,1))*np.median(b)\n",
    "    bd0 = b\n",
    "\n",
    "    #current error\n",
    "    nm = LA.norm(b-bd0)\n",
    "    nm0 = sys.float_info.max #initialize with largest possible float\n",
    "\n",
    "    #solving D*bd = m\n",
    "    #D and m have been divided through by A\n",
    "    #Mistake in expression for M; should be +1, not -1\n",
    "    M0 = s*np.ones((L,1))/A\n",
    "\n",
    "    #initialize D matrix\n",
    "    e = np.ones((L,1))\n",
    "    diagonals = [2, -8, 12, -8, 2]\n",
    "    D0 = diags(diagonals, np.arange(-2,3), shape=(L,L)).toarray()\n",
    "    \n",
    "    D0[0,0] = 2\n",
    "    D0[L-1,L-1] = 2\n",
    "\n",
    "    D0[1,0] = -4\n",
    "    D0[0,1] = -4\n",
    "    D0[L-1,L-2] = -4\n",
    "    D0[L-2,L-1]= -4\n",
    "\n",
    "    D0[1,1] = 10\n",
    "    D0[L-2,L-2] = 10\n",
    "\n",
    "    #index for iteration\n",
    "    i=0\n",
    "\n",
    "    while ((nm>10 or i<5) and i<30):\n",
    "        i=i+1\n",
    "        M = M0\n",
    "        D = D0\n",
    "        bd0 = bd\n",
    "        nm0=nm #not sure this is needed, nm0 not used in iteration\n",
    "\n",
    "        for j in np.arange(0,L):\n",
    "            if (bd[j]>b[j]):\n",
    "                M[j] = M[j] + 2*(B/A)*b[j]\n",
    "                D[j,j] = D[j,j] + 2*(B/A)\n",
    "\n",
    "        bd = solve(D,M).flatten() #need to flatten to convert to 1D array\n",
    "        nm = LA.norm(bd0-bd)\n",
    "    \n",
    "    b_subtract = b-bd\n",
    "    return b_subtract,bd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions for finding peaks and calculating areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "###returns indices for peaks for a given trace as well as the values at the peaks\n",
    "def find_trace_peaks(trace, min_distance=100, min_height=2.5):\n",
    "    \n",
    "    peak_idx, _ = find_peaks(trace, distance=min_distance, height=min_height)  \n",
    "    peak_val = trace[peak_idx]\n",
    "\n",
    "    return peak_idx, peak_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_peak_areas(start_nt, end_nt, trace, trace_nt, ctrl_start=200, ctrl_end=300):\n",
    "    #start_nt and end_nt should flank the peak of interest\n",
    "    #trace refers to the reading values (FU on the Bioanalyzer)\n",
    "    #trace_nt refers to the x-axis, or the nucleotides corresponding to different values in trace\n",
    "    #ctrl_start, and ctrl_end refer to P4P6 control, and is flanking a wider nucleotide window to account for accumulation\n",
    "    #of background, degraded RNAs\n",
    "    \n",
    "    #indices for P4P6\n",
    "    p4p6_start_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-ctrl_start))\n",
    "    p4p6_end_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-ctrl_end))\n",
    "\n",
    "    #indices for mRNA\n",
    "    first_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-start_nt))\n",
    "    last_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-end_nt)) \n",
    "    \n",
    "    #calculating areas\n",
    "    p4p6_area = np.trapz(y=trace[p4p6_start_idx:p4p6_end_idx], x=trace_nt[p4p6_start_idx:p4p6_end_idx])\n",
    "    background_area = np.trapz(y=[trace[first_idx], trace[last_idx]], x=[trace_nt[first_idx],trace_nt[last_idx]])\n",
    "    total_area = np.trapz(y=trace[first_idx:last_idx], x=trace_nt[first_idx:last_idx])\n",
    "    \n",
    "    subtracted_area = total_area-background_area\n",
    "    normalized_area = subtracted_area/p4p6_area\n",
    "    \n",
    "    return p4p6_area, background_area, total_area, subtracted_area, normalized_area\n",
    "\n",
    "def return_total_area(start_nt, end_nt, trace, trace_nt, ctrl_start=200, ctrl_end = 300, total_start = 200):\n",
    "    '''\n",
    "    start_nt and end_nt should flank the peak of interest\n",
    "    trace: signal (FU on the Bioanalyzer)\n",
    "    trace_nt: nucleotides corresponding to trace\n",
    "    ctrl_start: nucleotide to start measuring background from for entire trace\n",
    "    '''\n",
    "    #indices for P4P6\n",
    "    p4p6_start_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-ctrl_start))\n",
    "    p4p6_end_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-ctrl_end))\n",
    "\n",
    "    #indices for mRNA\n",
    "    first_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-start_nt))\n",
    "    last_idx = min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-end_nt)) \n",
    "    \n",
    "    #calculating areas:\n",
    "    #area for p4p6 control (also sometimes 25 nt area)\n",
    "    p4p6_area = np.trapz(y=trace[p4p6_start_idx:p4p6_end_idx], x=trace_nt[p4p6_start_idx:p4p6_end_idx])\n",
    "    #area for background\n",
    "    peak_background_area = np.trapz(y=[trace[first_idx], trace[last_idx]], x=[trace_nt[first_idx],trace_nt[last_idx]])\n",
    "    #peak area refers to full length peak of interest\n",
    "    peak_area = np.trapz(y=trace[first_idx:last_idx], x=trace_nt[first_idx:last_idx])\n",
    "    \n",
    "    #now calculating full background\n",
    "    control_start_idx =  min(range(len(trace_nt)), key=lambda i: abs(trace_nt[i]-total_start))\n",
    "    lane_background_area = np.trapz(y=trace[control_start_idx:last_idx], x=trace_nt[control_start_idx:last_idx])\n",
    "    \n",
    "#     #subtract out background and normalize\n",
    "#     subtracted_area = peak_area-background_area\n",
    "#     normalized_area = subtracted_area/p4p6_area\n",
    "    \n",
    "#     #now also normalize by the total amount of background present\n",
    "#     subtracted_lane = total_background - subtracted_area #returns the total background for the entire lane\n",
    "#     normalized_lane = peak_area/total_background #should return ~1 if the majority of the area is represented in peak\n",
    "    \n",
    "    return p4p6_area, peak_area, peak_background_area,lane_background_area\n",
    "\n",
    "def calc_frac_intact(times, norm_areas):\n",
    "    \n",
    "    init_val = float(norm_areas[0])\n",
    "    frac_intact = (norm_areas/init_val).clip(0)\n",
    "    \n",
    "    return frac_intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#returns indices, bootstrapped\n",
    "def bootstrap_inds(x):\n",
    "    bs_indices = np.random.choice(range(len(x)),len(x))\n",
    "    return bs_indices\n",
    "\n",
    "#function for exponential fitting\n",
    "def func(x, A, b, c):\n",
    "    return A*np.exp(-b*x)+c\n",
    "\n",
    "def exp_fit(frac_intact, timepoints, func, bs_iter = 1000, p0=(0.8,0.5,0)):\n",
    "    fit_coeffs = []\n",
    "    for i in np.arange(0,bs_iter,1):\n",
    "        \n",
    "        #just in case\n",
    "        frac_intact = np.clip(a=frac_intact, a_min=0, a_max=max(frac_intact))\n",
    "        \n",
    "        #generate bootstrap indices\n",
    "        bs_indices = bootstrap_inds(frac_intact)\n",
    "        \n",
    "        #generating data for fit\n",
    "        fit_t = [timepoints[i] for i in bs_indices]\n",
    "        fit_fracint = [frac_intact[i] for i in bs_indices]\n",
    "        \n",
    "        #exponential fit\n",
    "        popt, pcov = curve_fit(func, fit_t, fit_fracint, maxfev=5000, p0=p0)\n",
    "        \n",
    "        fit_coeffs.append((popt, pcov))\n",
    "        \n",
    "    return fit_coeffs\n",
    "\n",
    "\n",
    "def exp_fit_fixed(timepoints, frac_intact, bs_iter = 1000, p0=0.5):\n",
    "    \n",
    "    fit_coeffs = []\n",
    "    \n",
    "    for i in np.arange(0,bs_iter,1):\n",
    "        #just in case\n",
    "        frac_intact = np.clip(a=frac_intact, a_min=0, a_max=max(frac_intact))\n",
    "        \n",
    "        #generate bootstrap indices\n",
    "        bs_indices = bootstrap_inds(frac_intact)\n",
    "        \n",
    "        #generating data for fit\n",
    "        fit_t = [timepoints[i] for i in bs_indices]\n",
    "        fit_fracint = [frac_intact[i] for i in bs_indices]\n",
    "        \n",
    "        #exponential fit, fix exponential decay function to start at value at time point 0\n",
    "#         popt, pcov = curve_fit(lambda t,b: fit_fracint[0]*np.exp(-1*b*t),  fit_t,  fit_fracint, p0=p0, maxfev=5000, bounds=(0, 1))\n",
    "        popt, pcov = curve_fit(lambda t,b: np.exp(-1*b*t),  fit_t,  fit_fracint, p0=p0, maxfev=5000)\n",
    "\n",
    "        fit_coeffs.append((popt, pcov))\n",
    "    return fit_coeffs\n",
    "\n",
    "def log_transform_fit(timepoints, frac_intact, bs_iter=1000):\n",
    "    \n",
    "    fit_coeffs = []\n",
    "    \n",
    "    for i in np.arange(0,bs_iter, 1):\n",
    "        frac_intact = np.absolute(frac_intact)\n",
    "        \n",
    "        #generate bootstrap indices\n",
    "        bs_indices = bootstrap_inds(frac_intact)\n",
    "        \n",
    "        #generating data for fit\n",
    "        fit_t = [timepoints[i] for i in bs_indices][:8]\n",
    "        fit_fracint = [frac_intact[i] for i in bs_indices][:8]\n",
    "        \n",
    "        #doing a first order fit after log transform\n",
    "        fit = np.polyfit(fit_t, -1*np.log(fit_fracint), 1, w=np.sqrt(fit_fracint))\n",
    "        \n",
    "        fit_coeffs.append(fit[0])\n",
    "    \n",
    "    return fit_coeffs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of samples starts here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### appending file names from each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in sample map\n",
    "map_df = pd.read_csv('sample_nucleotide_filename.csv')\n",
    "# map_df = pd.read_csv('sample_nucleotide_filename_first6.csv')\n",
    "# map_df\n",
    "\n",
    "#match plate number to filename:\n",
    "filenames_df = pd.read_csv('platenumber_filename.csv')\n",
    "filenames_dict = dict(zip(filenames_df['Plate_Number'],filenames_df['File_Name']))\n",
    "\n",
    "data_dir = './processed_data/'\n",
    "#mapping plate number to filename, adding column to map\n",
    "filenames = []\n",
    "\n",
    "for filename, filenum in zip(map_df['Plate'], map_df['FileNumber']):\n",
    "    name = filenames_dict[filename]\n",
    "    name = 'nts-'+name+'_Sample'+str(filenum)+'.csv'\n",
    "#     print(name)\n",
    "    filenames.append(name)\n",
    "\n",
    "\"\"\"\n",
    "check that files exist\n",
    "commented out for now after checking, we're good\n",
    "\"\"\"\n",
    "\n",
    "# for filename in filenames:\n",
    "#     print(path.exists(data_dir+filename))\n",
    "\n",
    "map_df['FileName'] = filenames\n",
    "# map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_nts_list = []\n",
    "start_nt_list = []\n",
    "end_nt_list = []\n",
    "p4p6_area_list = []\n",
    "bg_area_list = []\n",
    "total_area_list = []\n",
    "subtract_area_list = []\n",
    "normalized_area_list = []\n",
    "signal_normalized_area_list = []\n",
    "\n",
    "plot_dir = './plots/'\n",
    "\n",
    "peaks_nt_dict = {}\n",
    "# Iterate through the list of samples, and return a df that has nucleotides and background subtracted values\n",
    "for row in map_df.itertuples():\n",
    "    clf()\n",
    "    #read in dataframe for given sample\n",
    "    sample_df = pd.read_csv(data_dir+row.FileName)\n",
    "    \n",
    "    #extract time series and nucleotides, let's clip to just the first third (up to ~1400 nucleotides)\n",
    "    array_len = len(sample_df['Nucleotides'])\n",
    "    clip_len = int(array_len/2.2)\n",
    "    \n",
    "    nts = np.array(sample_df['Nucleotides'][:clip_len])\n",
    "    trace = np.array(sample_df['Value'][:clip_len])\n",
    "    \n",
    "    plot(nts, trace, label=row.Sample+'_'+row.Nucleotide+'_'+str(row.Timepoint))\n",
    "    title(row.Sample+'_'+row.Nucleotide+'_'+str(row.Timepoint))\n",
    "    xlabel('Nucleotides')\n",
    "    ylabel('Signal (FU)')\n",
    "    tight_layout()\n",
    "    \n",
    "    savefig(plot_dir+row.Sample+'_'+row.Nucleotide+'_'+str(row.Timepoint)+'.png', dpi=300)\n",
    "    clf()\n",
    "    \n",
    "    ###plotting the background subtracted trace\n",
    "    trace_norm,_ = baseline_xi(trace)\n",
    "    plot(nts, trace_norm, label=row.Sample+'_'+row.Nucleotide+'_'+str(row.Timepoint))\n",
    "    title(row.Sample+'_'+row.Nucleotide+'_'+str(row.Timepoint))\n",
    "    xlabel('Nucleotides')\n",
    "    ylabel('Signal (FU)')\n",
    "    tight_layout()\n",
    "    \n",
    "#     savefig(plot_dir+'normalized-'+row.Sample+'_'+row.Nucleotide+'_'+str(row.Timepoint)+'.png', dpi=300)\n",
    "    clf()\n",
    "    \n",
    "    \n",
    "    if (row.Timepoint == 0):\n",
    "        peak_idx, peak_val = find_trace_peaks(trace,min_distance=100, min_height=1)\n",
    "        peak_nts = nts[peak_idx]\n",
    "        peak_nts_list.append(peak_nts)\n",
    "        \n",
    "        start_nt = nts[peak_idx][-1]-100\n",
    "        end_nt = nts[peak_idx][-1]+100\n",
    "        \n",
    "        start_nt_list.append(start_nt)\n",
    "        end_nt_list.append(end_nt)\n",
    "        \n",
    "        peak_assign_dict = {}\n",
    "        peak_assign_dict['start_nt'] = start_nt\n",
    "        peak_assign_dict['end_nt'] = end_nt\n",
    "        peak_assign_dict['peaks'] = peak_nts\n",
    "        \n",
    "        peaks_nt_dict[(row.Sample, row.Nucleotide)] = peak_assign_dict\n",
    "\n",
    "    else:\n",
    "        time_0_dict = peaks_nt_dict[(row.Sample, row.Nucleotide)]\n",
    "        peak_nts_list.append(time_0_dict['peaks'])\n",
    "        start_nt_list.append(time_0_dict['start_nt'])\n",
    "        end_nt_list.append(time_0_dict['end_nt'])\n",
    "        \n",
    "        start_nt = time_0_dict['start_nt']\n",
    "        end_nt = time_0_dict['end_nt']\n",
    "\n",
    "\n",
    "#     #integrate at specified nucleotides per sample\n",
    "#     start_nt = nts[peak_idx][-1]-100\n",
    "#     end_nt = nts[peak_idx][-1]+100\n",
    "#     start_nt_list.append(start_nt)\n",
    "#     end_nt_list.append(end_nt)\n",
    "    \n",
    "    p4p6, background, total, subtract, normalized = return_peak_areas(start_nt, end_nt, trace, nts, ctrl_start=20, ctrl_end=30)\n",
    "    p4p6_area_list.append(p4p6)\n",
    "    bg_area_list.append(background)\n",
    "    total_area_list.append(total)\n",
    "    subtract_area_list.append(subtract)\n",
    "    normalized_area_list.append(normalized)\n",
    "    \n",
    "    _,_,control_area_25, _, _ = return_peak_areas(start_nt=5, end_nt = 50, trace=trace, trace_nt=nts)\n",
    "    double_normalized = normalized/control_area_25\n",
    "    signal_normalized_area_list.append(double_normalized)\n",
    "\n",
    "map_df = map_df.assign(peak_nts = peak_nts_list, start_nt = start_nt_list, end_nt = end_nt_list,\\\n",
    "              p4p6_area = p4p6_area_list, background_area = bg_area_list, total_area = total_area_list,\\\n",
    "              subtracted_area = subtract_area_list, normalized_area = normalized_area_list, double_normalized = signal_normalized_area_list)\n",
    "\n",
    "map_df\n",
    "#export dataframe to .csv for recordkeeping\n",
    "map_df.to_csv('12-10-2020_analyzed_samples_doublenormalized.csv')\n",
    "# map_df.to_csv('12-10-2020_analyzed_samples_doublenormalized_first6.csv')\n",
    "\n",
    "#plot configuration\n",
    "# title('Background Subtracted Traces')\n",
    "# xlabel('Nucleotides')\n",
    "# ylabel('Signal (FU)')\n",
    "# tight_layout()\n",
    "# savefig('10-21-2020_traces.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all combinations of sample and nucleotide type\n",
    "samples = set(zip(map_df['Sample'], map_df['Nucleotide']))\n",
    "\n",
    "sample_dfs = []\n",
    "sample_fits = {}\n",
    "all_fits = {}\n",
    "for sample in sorted(samples):\n",
    "    rna_sample = sample[0]\n",
    "    nucleotide = sample[1]\n",
    "\n",
    "    working_df = map_df[(map_df['Sample']==rna_sample) & (map_df['Nucleotide']==nucleotide)]\n",
    "#     working_df\n",
    "    \n",
    "    norm_areas = np.array(working_df['normalized_area'])\n",
    "#     norm_areas = np.array(working_df['double_normalized'])\n",
    "    times = np.array(working_df['Timepoint'])\n",
    "    \n",
    "    frac_intact = calc_frac_intact(times, norm_areas)\n",
    "    working_df['Frac_Intact'] = frac_intact\n",
    "    \n",
    "    plot(times, frac_intact, label=sample, linewidth=3)\n",
    "    \n",
    "    fit_dict = {}\n",
    "    \n",
    "    try:\n",
    "        print('Trying an exponential fit...'+str(sample))\n",
    "        fits = exp_fit(timepoints=times, frac_intact=frac_intact, func=func)\n",
    "        kdeg = np.mean(fits)\n",
    "        kdeg_err = np.std(fits)\n",
    "        print(kdeg)\n",
    "        print(kdeg_err)\n",
    "        fit_dict['kdeg'] = kdeg\n",
    "        fit_dict['kdeg_err'] = kdeg_err\n",
    "        \n",
    "    except RuntimeError:\n",
    "        print('Could not converge for...'+str(sample))\n",
    "        fit_dict['kdeg'] = 'Error'\n",
    "        fit_dict['kdeg_err'] = 'Error'\n",
    "        continue\n",
    "    \n",
    "    sample_fits[sample] = fit_dict\n",
    "    all_fits[sample] = fits\n",
    "# sample_fits\n",
    "legend(loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=14)\n",
    "title('Fraction Intact')\n",
    "xlabel('Time (hours)')\n",
    "ylabel('Fraction Intact')\n",
    "\n",
    "tight_layout()\n",
    "\n",
    "# savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df = pd.DataFrame.from_dict(sample_fits, orient='index')\n",
    "fit_df.to_csv('12-10-2020_exponential_fits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normaling each lane by how much degradation product exists aka % intact per lane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "- normalize per lane, based on how much degradation product in each lane\n",
    "- for each lane, normalize intensity by what % of product is desired band\n",
    "- then divide` % full length product by the % at 0 hrs (should be ~1) to get fraction intact over time\n",
    "- at the end, print scatterplot of fraction intact over time, and then the exponential fit (average from bootstrap method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's take the first sample from lane_df\n",
    "# test_df = map_df[map_df['Sample']=='hHBB_10422827_Ribotree_Random_sup_1_hHBB']\n",
    "# test_df\n",
    "\n",
    "peak_nts_list = []\n",
    "start_nt_list = []\n",
    "end_nt_list = []\n",
    "p4p6_area_list = []\n",
    "peak_area_list = []\n",
    "peak_background_area_list = []\n",
    "lane_background_area_list = []\n",
    "peaks_nt_dict = {}\n",
    "\n",
    "#iterating through the dataframe\n",
    "for row in map_df.itertuples():\n",
    "    \n",
    "    sample_df = pd.read_csv(data_dir+row.FileName)\n",
    "    \n",
    "    #extract time series and nucleotides, let's clip to just the first third (up to ~1400 nucleotides)\n",
    "    array_len = len(sample_df['Nucleotides'])\n",
    "    clip_len = int(array_len/2.2)\n",
    "    \n",
    "    nts = np.array(sample_df['Nucleotides'][:clip_len])\n",
    "    trace = np.array(sample_df['Value'][:clip_len])\n",
    "    \n",
    "    ###plotting the background subtracted trace\n",
    "    trace_norm,_ = baseline_xi(trace)\n",
    "    \n",
    "    if (row.Timepoint == 0):\n",
    "        peak_idx, peak_val = find_trace_peaks(trace,min_distance=100, min_height=1)\n",
    "        peak_nts = nts[peak_idx]\n",
    "        peak_nts_list.append(peak_nts)\n",
    "        \n",
    "        start_nt = nts[peak_idx][-1]-100\n",
    "        end_nt = nts[peak_idx][-1]+100\n",
    "        \n",
    "        start_nt_list.append(start_nt)\n",
    "        end_nt_list.append(end_nt)\n",
    "        \n",
    "        peak_assign_dict = {}\n",
    "        peak_assign_dict['start_nt'] = start_nt\n",
    "        peak_assign_dict['end_nt'] = end_nt\n",
    "        peak_assign_dict['peaks'] = peak_nts\n",
    "        \n",
    "        peaks_nt_dict[(row.Sample, row.Nucleotide)] = peak_assign_dict\n",
    "\n",
    "    else:\n",
    "        time_0_dict = peaks_nt_dict[(row.Sample, row.Nucleotide)]\n",
    "        peak_nts_list.append(time_0_dict['peaks'])\n",
    "        start_nt_list.append(time_0_dict['start_nt'])\n",
    "        end_nt_list.append(time_0_dict['end_nt'])\n",
    "        \n",
    "        start_nt = time_0_dict['start_nt']\n",
    "        end_nt = time_0_dict['end_nt']\n",
    "    \n",
    "    p4p6_area, peak_area, peak_background_area, lane_background_area = return_total_area(start_nt, end_nt, trace, nts, ctrl_start=15, ctrl_end=40)\n",
    "\n",
    "    \n",
    "    p4p6_area_list.append(p4p6_area)\n",
    "    peak_area_list.append(peak_area)\n",
    "    peak_background_area_list.append(peak_background_area)\n",
    "    lane_background_area_list.append(lane_background_area)\n",
    "    \n",
    "#     _,_,control_area_25, _, _ = return_peak_areas(start_nt=5, end_nt = 50, trace=trace, trace_nt=nts)\n",
    "#     double_normalized = normalized/control_area_25\n",
    "#     signal_normalized_area_list.append(double_normalized)\n",
    "    \n",
    "    \n",
    "map_df = map_df.assign(peak_nts = peak_nts_list, \n",
    "                         start_nt = start_nt_list, \n",
    "                         end_nt = end_nt_list,\n",
    "                         p4p6_area = p4p6_area_list,\n",
    "                         peak_area = peak_area_list,\n",
    "                         peak_background_area = peak_background_area_list,\n",
    "                         lane_background_area = lane_background_area_list)\n",
    "map_df = map_df.dropna(axis=1)\n",
    "map_df.to_csv('map_allareas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df['peak_area_subtracted'] = map_df['peak_area']-map_df['peak_background_area']\n",
    "map_df['fraction_intact'] = map_df['peak_area_subtracted']/map_df['lane_background_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "plot_dir = './plots/'\n",
    "\n",
    "#all combinations of sample and nucleotide type\n",
    "samples = set(zip(map_df['Sample'], map_df['Nucleotide']))\n",
    "# samples=samples[0]\n",
    "\n",
    "sample_dfs = []\n",
    "sample_fits = {}\n",
    "all_fits = {}\n",
    "\n",
    "num_plots = len(samples)\n",
    "num_rows = round(num_plots/4, 1)\n",
    "num_columns = num_plots/num_rows\n",
    "figure(figsize=(num_rows*3+5, num_columns*4+2))\n",
    "sample_dfs = []\n",
    "sample_fits = {}\n",
    "all_fits = {}\n",
    "\n",
    "for i, sample in tqdm(enumerate(sorted(samples))):\n",
    "    \n",
    "    subplot(num_rows, num_columns, i+1)\n",
    "    \n",
    "    rna_sample = sample[0]\n",
    "    nucleotide = sample[1]\n",
    "\n",
    "    #extracting the df for that sample, nucleotide combo\n",
    "    working_df = map_df[(map_df['Sample']==rna_sample) & (map_df['Nucleotide']==nucleotide)]\n",
    "    \n",
    "    #times are time points (t), fraction intact values (fi)\n",
    "    #to be used in fi = np.exp(-b*t) fit for b coefficient --> kdeg calculation\n",
    "    times = np.array(working_df['Timepoint'])[:8]\n",
    "    frac_intact = np.array(working_df['fraction_intact'])[:8]\n",
    "\n",
    "    scatter(times, frac_intact, label='Data', s=20, marker='o')\n",
    "    \n",
    "    fit_dict = {}\n",
    "    try:\n",
    "        print('Trying an exponential fit...'+str(sample))\n",
    "        fits = np.array(log_transform_fit(timepoints = times, frac_intact=frac_intact, bs_iter=1000))\n",
    "        kdeg = np.average(fits)\n",
    "        kdeg_err = np.std(fits)\n",
    "        print('kdeg: '+str(kdeg))\n",
    "        print('kdeg_err: '+str(kdeg_err))\n",
    "        fit_dict['kdeg'] = kdeg\n",
    "        fit_dict['kdeg_err'] = kdeg_err\n",
    "        \n",
    "#         plotting fit\n",
    "        plot(np.arange(0,24,0.05), frac_intact[0]*np.exp(-1*kdeg*np.arange(0,24,0.05)), linewidth=3, label='Fit')\n",
    "        \n",
    "    except RuntimeError:\n",
    "        print('Could not converge for...'+str(sample))\n",
    "        fit_dict['kdeg'] = 'Error'\n",
    "        fit_dict['kdeg_err'] = 'Error'\n",
    "        continue\n",
    "    \n",
    "    sample_fits[sample] = fit_dict\n",
    "    all_fits[sample] = fits\n",
    "    \n",
    "    legend(loc='upper left', bbox_to_anchor=(1.05,1), fontsize=14)\n",
    "    title('{}'.format(rna_sample), fontsize=12)\n",
    "    xlabel('Time (hours)')\n",
    "    ylabel('Fraction Intact')\n",
    "    tight_layout()\n",
    "\n",
    "savefig(plot_dir+'numpy_exponential_fit.pdf')\n",
    "#     clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(sample_fits, orient='index').to_csv('12-10_expfits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expfit_1210_df = pd.read_csv('12-10_expfits.csv')\n",
    "\n",
    "#returning rank\n",
    "kdeg_1210 = expfit_1210_df['kdeg_12-10']\n",
    "kdeg_1202 = expfit_1210_df['kdeg_12-02']\n",
    "\n",
    "def array_rank(array):\n",
    "    temp = array.argsort()\n",
    "    ranks = numpy.empty_like(temp)\n",
    "    ranks[temp] = numpy.arange(len(array))\n",
    "    return ranks\n",
    "\n",
    "expfit_1210_df['rank_12-10'] = array_rank(kdeg_1210)\n",
    "expfit_1210_df['rank_12-02'] = array_rank(kdeg_1202)\n",
    "\n",
    "# expfit_1210_df\n",
    "\n",
    "sns.scatterplot(data=expfit_1210_df, x='rank_12-10', y='rank_12-02', s=50)\n",
    "title('Comparing relative ranks', fontsize=14)\n",
    "xlabel('Relative Rank (12-10)', fontsize=14)\n",
    "ylabel('Relative Rank (12-02)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing Kendall-Tau:\n",
    "kt_coeff, kt_pval = sp.stats.kendalltau(expfit_1210_df['rank_12-10'], expfit_1210_df['rank_12-02'])\n",
    "kt_coeff\n",
    "kt_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expfit_1210_df.to_csv('kdeg_ranking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(expfit_1210_df['kdeg_12-10'], label='12-10 (10 time points)')\n",
    "sns.distplot(expfit_1210_df['kdeg_12-02'], label='12-02 (4 time points)')\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=map_df[map_df['Sample']=='hHBB_10383581_START_reference_hHBB']\n",
    "test_df['fraction_intact'] = test_df['fraction_intact'].clip(0)\n",
    "\n",
    "sns.scatterplot(data=test_df, x='Timepoint', y='fraction_intact')\n",
    "\n",
    "times = np.array(test_df['Timepoint'])\n",
    "frac_intact = np.array(test_df['fraction_intact'])\n",
    "\n",
    "# times\n",
    "# frac_intact\n",
    "\n",
    "fits = exp_fit_fixed(timepoints=times, frac_intact=frac_intact, bs_iter=1000)\n",
    "\n",
    "\n",
    "# fits\n",
    "\n",
    "scatter(times, frac_intact,marker='x', s=100)\n",
    "coeffs = []\n",
    "\n",
    "for i,fit in enumerate(fits):\n",
    "    y=np.exp(-1*kdeg*times)\n",
    "    plot(times, y)\n",
    "    coeffs.append(fit)\n",
    "#     kdeg = fit[0]\n",
    "#     if kdeg<0:\n",
    "#         print(i)\n",
    "#         print(fit)\n",
    "#         pass\n",
    "#     else:\n",
    "#         y=frac_intact[0]*np.exp(-1*kdeg*times)\n",
    "#         plot(times, y)\n",
    "#         coeffs.append(fit)\n",
    "        \n",
    "# legend()\n",
    "\n",
    "# coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subplot of log transformed fraction intact values to check linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = set(zip(map_df['Sample'], map_df['Nucleotide']))\n",
    "\n",
    "num_plots = len(samples)\n",
    "num_rows = round(num_plots/4, 1)\n",
    "num_columns = num_plots/num_rows\n",
    "figure(figsize=(num_rows*3+5, num_columns*4+2))\n",
    "# sample_dfs = []\n",
    "# sample_fits = {}\n",
    "# all_fits = {}\n",
    "\n",
    "for i, sample in tqdm(enumerate(sorted(samples))):\n",
    "    \n",
    "    subplot(num_rows, num_columns, i+1)\n",
    "    rna_sample = sample[0]\n",
    "    nucleotide = sample[1]\n",
    "\n",
    "    #extracting the df for that sample, nucleotide combo\n",
    "    working_df = map_df[(map_df['Sample']==rna_sample) & (map_df['Nucleotide']==nucleotide)]\n",
    "    \n",
    "    #times are time points (t), fraction intact values (fi)\n",
    "    #to be used in fi = np.exp(-b*t) fit for b coefficient --> kdeg calculation\n",
    "    times = np.array(working_df['Timepoint'])[:8]\n",
    "    frac_intact = np.array(working_df['fraction_intact'])[:8]\n",
    "    \n",
    "#     clf()\n",
    "    scatter(times, np.log(frac_intact), s=20, marker='o')\n",
    "    \n",
    "    title('{}'.format(rna_sample), fontsize=12)\n",
    "    xlabel('Time (hours)')\n",
    "    ylabel('ln(Fraction Intact)')\n",
    "\n",
    "tight_layout()\n",
    "\n",
    "# savefig(plot_dir+'logy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=map_df[map_df['Sample']=='hHBB_10383581_START_reference_hHBB']\n",
    "# test_df['fraction_intact'] = test_df['fraction_intact'].clip()\n",
    "\n",
    "# sns.scatterplot(data=test_df, x='Timepoint', y='fraction_intact')\n",
    "\n",
    "times = np.array(test_df['Timepoint'])\n",
    "frac_intact = np.array(test_df['fraction_intact'])\n",
    "\n",
    "test_df['fraction_intact']\n",
    "frac_intact\n",
    "-1*np.log(frac_intact)\n",
    "\n",
    "scatter(times, -1*np.log(frac_intact))\n",
    "ylabel('-log(fraction intact)', fontsize=14)\n",
    "xlabel('Hours')\n",
    "xticks(fontsize=12)\n",
    "yticks(fontsize=12)\n",
    "tight_layout()\n",
    "\n",
    "# np.polyfit(times, np.log(frac_intact), 1, w=np.sqrt(frac_intact))\n",
    "# np.polyfit(times, -1*np.log(frac_intact), 1)\n",
    "\n",
    "# scatter(times, frac_intact,marker='x', s=100)\n",
    "# coeffs = []\n",
    "\n",
    "# for i,fit in enumerate(fits):\n",
    "#     y=np.exp(-1*kdeg*times)\n",
    "#     plot(times, y)\n",
    "#     coeffs.append(fit)\n",
    "#     kdeg = fit[0]\n",
    "#     if kdeg<0:\n",
    "#         print(i)\n",
    "#         print(fit)\n",
    "#         pass\n",
    "#     else:\n",
    "#         y=frac_intact[0]*np.exp(-1*kdeg*times)\n",
    "#         plot(times, y)\n",
    "#         coeffs.append(fit)\n",
    "        \n",
    "# legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_coeffs = np.average(coeffs, axis=0)\n",
    "float(average_coeffs[0])\n",
    "\n",
    "scatter(times, frac_intact,marker='x', s=100)\n",
    "plot(times, frac_intact[0]*np.exp(-1*float(average_coeffs[0])*times))\n",
    "average_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_areas = {}\n",
    "for sample in samples:\n",
    "    sample_name = sample[0]\n",
    "    sample_nt = sample[1]\n",
    "    init_areas[sample] = float(map_df[(map_df['Timepoint']==0)&(map_df['Sample']==sample_name)\n",
    "                               &(map_df['Nucleotide']==sample_nt)]['normalized_area'])\n",
    "\n",
    "frac_intact_list = []\n",
    "for row in map_df.itertuples():\n",
    "    sample_nt = (row.Sample, row.Nucleotide)\n",
    "    frac_intact = np.maximum(row.normalized_area/init_areas[sample_nt], 0)\n",
    "    frac_intact_list.append(frac_intact)\n",
    "\n",
    "map_df['Fraction_intact'] = frac_intact_list\n",
    "\n",
    "map_df.to_csv('12-10-2020_fraction_intact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flexible peak identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_map_df = map_df\n",
    "\n",
    "peak_nts_list = []\n",
    "all_peak_nts = []\n",
    "start_nt_list = []\n",
    "end_nt_list = []\n",
    "p4p6_area_list = []\n",
    "peak_area_list = []\n",
    "peak_background_area_list = []\n",
    "lane_background_area_list = []\n",
    "peaks_nt_dict = {}\n",
    "\n",
    "    \n",
    "# iterating through the dataframe\n",
    "for i,row in enumerate(flex_map_df.itertuples()):\n",
    "    \n",
    "    sample_df = pd.read_csv(data_dir+row.FileName)\n",
    "    \n",
    "    #extract time series and nucleotides, let's clip to just the first third (up to ~1400 nucleotides)\n",
    "    array_len = len(sample_df['Nucleotides'])\n",
    "    clip_len = int(array_len/2.2)\n",
    "    \n",
    "    nts = np.array(sample_df['Nucleotides'][:clip_len])\n",
    "    trace = np.array(sample_df['Value'][:clip_len])\n",
    "    \n",
    "    ###plotting the background subtracted trace\n",
    "    trace_norm,_ = baseline_xi(trace)\n",
    "    \n",
    "    peak_idx, peak_val = find_trace_peaks(trace,min_distance=100, min_height=1)\n",
    "    \n",
    "    all_peak_nts.append(nts[peak_idx])\n",
    "    \n",
    "    #checking if a real peak exists:\n",
    "    if nts[peak_idx][-1]>800:\n",
    "        peak_nts = nts[peak_idx][-1]\n",
    "    else:\n",
    "        peak_nts = peak_nts_list[-1]\n",
    "        \n",
    "    peak_nts_list.append(peak_nts)\n",
    "    \n",
    "    start_nt = peak_nts-100\n",
    "    end_nt = peak_nts+100\n",
    "        \n",
    "    start_nt_list.append(start_nt)\n",
    "    end_nt_list.append(end_nt)\n",
    "\n",
    "    peak_assign_dict = {}\n",
    "    peak_assign_dict['start_nt'] = start_nt\n",
    "    peak_assign_dict['end_nt'] = end_nt\n",
    "    peak_assign_dict['peaks'] = peak_nts\n",
    "\n",
    "    peaks_nt_dict[(row.Sample, row.Nucleotide)] = peak_assign_dict    \n",
    "    p4p6_area, peak_area, peak_background_area, lane_background_area = return_total_area(start_nt, end_nt, trace, nts, ctrl_start=15, ctrl_end=40)\n",
    "\n",
    "    p4p6_area_list.append(p4p6_area)\n",
    "    peak_area_list.append(peak_area)\n",
    "    peak_background_area_list.append(peak_background_area)\n",
    "    lane_background_area_list.append(lane_background_area)\n",
    "    \n",
    "flex_map_df = flex_map_df.assign(peak_nts = peak_nts_list, \n",
    "                         start_nt = start_nt_list, \n",
    "                         end_nt = end_nt_list,\n",
    "                         p4p6_area = p4p6_area_list,\n",
    "                         peak_area = peak_area_list,\n",
    "                         peak_background_area = peak_background_area_list,\n",
    "                         lane_background_area = lane_background_area_list,\n",
    "                         all_id_peaks = all_peak_nts)\n",
    "\n",
    "# flex_map_df\n",
    "\n",
    "flex_map_df['peak_area_subtracted'] = flex_map_df['peak_area']-flex_map_df['peak_background_area']\n",
    "flex_map_df['fraction_intact'] = flex_map_df['peak_area_subtracted']/flex_map_df['lane_background_area']\n",
    "# map_df = map_df.dropna(axis=1)\n",
    "flex_map_df.to_csv('flex_map_allareas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = set(zip(flex_map_df['Sample'], flex_map_df['Nucleotide']))\n",
    "\n",
    "num_plots = len(samples)\n",
    "num_rows = round(num_plots/4, 1)\n",
    "num_columns = num_plots/num_rows\n",
    "figure(figsize=(num_rows*3+5, num_columns*4+2))\n",
    "# sample_dfs = []\n",
    "# sample_fits = {}\n",
    "# all_fits = {}\n",
    "\n",
    "for i, sample in tqdm(enumerate(sorted(samples))):\n",
    "    \n",
    "    subplot(num_rows, num_columns, i+1)\n",
    "    rna_sample = sample[0]\n",
    "    nucleotide = sample[1]\n",
    "\n",
    "    #extracting the df for that sample, nucleotide combo\n",
    "    working_df = flex_map_df[(flex_map_df['Sample']==rna_sample) & (flex_map_df['Nucleotide']==nucleotide)]\n",
    "    \n",
    "    #times are time points (t), fraction intact values (fi)\n",
    "    #to be used in fi = np.exp(-b*t) fit for b coefficient --> kdeg calculation\n",
    "    times = np.array(working_df['Timepoint'])[:8]\n",
    "    frac_intact = np.array(working_df['fraction_intact'])[:8]\n",
    "    \n",
    "#     clf()\n",
    "    scatter(times, np.log(frac_intact), s=20, marker='o')\n",
    "    \n",
    "    title('{}'.format(rna_sample), fontsize=12)\n",
    "    xlabel('Time (hours)')\n",
    "    ylabel('ln(Fraction Intact)')\n",
    "\n",
    "tight_layout()\n",
    "\n",
    "savefig(plot_dir+'flex_peaks_logy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "plot_dir = './plots/'\n",
    "\n",
    "#all combinations of sample and nucleotide type\n",
    "samples = set(zip(flex_map_df['Sample'], flex_map_df['Nucleotide']))\n",
    "# samples=samples[0]\n",
    "\n",
    "sample_dfs = []\n",
    "sample_fits = {}\n",
    "all_fits = {}\n",
    "\n",
    "num_plots = len(samples)\n",
    "num_rows = round(num_plots/4, 1)\n",
    "num_columns = num_plots/num_rows\n",
    "figure(figsize=(num_rows*3+5, num_columns*4+2))\n",
    "sample_dfs = []\n",
    "sample_fits = {}\n",
    "all_fits = {}\n",
    "\n",
    "for i, sample in tqdm(enumerate(sorted(samples))):\n",
    "    \n",
    "    subplot(num_rows, num_columns, i+1)\n",
    "    \n",
    "    rna_sample = sample[0]\n",
    "    nucleotide = sample[1]\n",
    "\n",
    "    #extracting the df for that sample, nucleotide combo\n",
    "    working_df = flex_map_df[(flex_map_df['Sample']==rna_sample) & (flex_map_df['Nucleotide']==nucleotide)]\n",
    "    \n",
    "    #times are time points (t), fraction intact values (fi)\n",
    "    #to be used in fi = np.exp(-b*t) fit for b coefficient --> kdeg calculation\n",
    "    times = np.array(working_df['Timepoint'])[:8]\n",
    "    frac_intact = np.array(working_df['fraction_intact'])[:8]\n",
    "\n",
    "    scatter(times, frac_intact, label='Data', s=20, marker='o')\n",
    "    \n",
    "    fit_dict = {}\n",
    "    try:\n",
    "        print('Trying an exponential fit...'+str(sample))\n",
    "        fits = np.array(log_transform_fit(timepoints = times, frac_intact=frac_intact, bs_iter=1000))\n",
    "        kdeg = np.average(fits)\n",
    "        kdeg_err = np.std(fits)\n",
    "        print('kdeg: '+str(kdeg))\n",
    "        print('kdeg_err: '+str(kdeg_err))\n",
    "        fit_dict['kdeg'] = kdeg\n",
    "        fit_dict['kdeg_err'] = kdeg_err\n",
    "        \n",
    "#         plotting fit\n",
    "        plot(np.arange(0,24,0.05), frac_intact[0]*np.exp(-1*kdeg*np.arange(0,24,0.05)), linewidth=3, label='Fit')\n",
    "        \n",
    "    except RuntimeError:\n",
    "        print('Could not converge for...'+str(sample))\n",
    "        fit_dict['kdeg'] = 'Error'\n",
    "        fit_dict['kdeg_err'] = 'Error'\n",
    "        continue\n",
    "    \n",
    "    sample_fits[sample] = fit_dict\n",
    "    all_fits[sample] = fits\n",
    "    \n",
    "    legend(loc='upper left', bbox_to_anchor=(1.05,1), fontsize=14)\n",
    "    title('{}'.format(rna_sample), fontsize=12)\n",
    "    xlabel('Time (hours)')\n",
    "    ylabel('Fraction Intact')\n",
    "    tight_layout()\n",
    "\n",
    "savefig(plot_dir+'flex_peaks_numpy_exponential_fit.pdf')\n",
    "#     clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(sample_fits, orient='index').to_csv('12-10_flex_peaks_expfits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only using four time points like 12-02 \n",
    "#### 0, 1, 3, 5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in sample map\n",
    "map_4tps_df = pd.read_csv('sample_nucleotide_filename.csv')\n",
    "map_4tps_df = map_4tps_df[map_4tps_df['Timepoint'].isin([0.0, 1.0, 3.0, 5.0])]\n",
    "\n",
    "#match plate number to filename:\n",
    "filenames_df = pd.read_csv('platenumber_filename.csv')\n",
    "filenames_dict = dict(zip(filenames_df['Plate_Number'],filenames_df['File_Name']))\n",
    "\n",
    "data_dir = './processed_data/'\n",
    "#mapping plate number to filename, adding column to map\n",
    "filenames = []\n",
    "\n",
    "for filename, filenum in zip(map_4tps_df['Plate'], map_4tps_df['FileNumber']):\n",
    "    name = filenames_dict[filename]\n",
    "    name = 'nts-'+name+'_Sample'+str(filenum)+'.csv'\n",
    "    filenames.append(name)\n",
    "\n",
    "map_4tps_df['FileName'] = filenames\n",
    "\n",
    "peak_nts_list = []\n",
    "all_peak_nts = []\n",
    "start_nt_list = []\n",
    "end_nt_list = []\n",
    "p4p6_area_list = []\n",
    "peak_area_list = []\n",
    "peak_background_area_list = []\n",
    "lane_background_area_list = []\n",
    "peaks_nt_dict = {}\n",
    "    \n",
    "# iterating through the dataframe\n",
    "for i,row in enumerate(map_4tps_df.itertuples()):\n",
    "    \n",
    "    sample_df = pd.read_csv(data_dir+row.FileName)\n",
    "    \n",
    "    #extract time series and nucleotides, let's clip to just the first third (up to ~1400 nucleotides)\n",
    "    array_len = len(sample_df['Nucleotides'])\n",
    "    clip_len = int(array_len/2.2)\n",
    "    \n",
    "    nts = np.array(sample_df['Nucleotides'][:clip_len])\n",
    "    trace = np.array(sample_df['Value'][:clip_len])\n",
    "    \n",
    "    ###plotting the background subtracted trace\n",
    "    trace_norm,_ = baseline_xi(trace)\n",
    "    \n",
    "    peak_idx, peak_val = find_trace_peaks(trace,min_distance=100, min_height=1)\n",
    "    \n",
    "    all_peak_nts.append(nts[peak_idx])\n",
    "    \n",
    "    #checking if a real peak exists:\n",
    "    if nts[peak_idx][-1]>800:\n",
    "        peak_nts = nts[peak_idx][-1]\n",
    "    else:\n",
    "        peak_nts = peak_nts_list[-1]\n",
    "        \n",
    "    peak_nts_list.append(peak_nts)\n",
    "    \n",
    "    start_nt = peak_nts-100\n",
    "    end_nt = peak_nts+100\n",
    "        \n",
    "    start_nt_list.append(start_nt)\n",
    "    end_nt_list.append(end_nt)\n",
    "\n",
    "    p4p6_area, peak_area, peak_background_area, lane_background_area = return_total_area(start_nt, end_nt, trace, nts, ctrl_start=15, ctrl_end=40)\n",
    "\n",
    "    p4p6_area_list.append(p4p6_area)\n",
    "    peak_area_list.append(peak_area)\n",
    "    peak_background_area_list.append(peak_background_area)\n",
    "    lane_background_area_list.append(lane_background_area)\n",
    "    \n",
    "map_4tps_df = map_4tps_df.assign(peak_nts = peak_nts_list, \n",
    "                         start_nt = start_nt_list, \n",
    "                         end_nt = end_nt_list,\n",
    "                         p4p6_area = p4p6_area_list,\n",
    "                         peak_area = peak_area_list,\n",
    "                         peak_background_area = peak_background_area_list,\n",
    "                         lane_background_area = lane_background_area_list,\n",
    "                         all_id_peaks = all_peak_nts)\n",
    "\n",
    "map_4tps_df['peak_area_subtracted'] = map_4tps_df['peak_area']-map_4tps_df['peak_background_area']\n",
    "map_4tps_df['fraction_intact'] = map_4tps_df['peak_area_subtracted']/map_4tps_df['lane_background_area']\n",
    "map_4tps_df = map_4tps_df.dropna(axis=1)\n",
    "map_4tps_df.to_csv('map_4tps_map_allareas.csv')\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "plot_dir = './plots/'\n",
    "\n",
    "#all combinations of sample and nucleotide type\n",
    "samples = set(zip(flex_map_df['Sample'], flex_map_df['Nucleotide']))\n",
    "# samples=samples[0]\n",
    "\n",
    "sample_dfs = []\n",
    "sample_fits = {}\n",
    "all_fits = {}\n",
    "\n",
    "num_plots = len(samples)\n",
    "num_rows = round(num_plots/4, 1)\n",
    "num_columns = num_plots/num_rows\n",
    "figure(figsize=(num_rows*3+5, num_columns*4+2))\n",
    "sample_dfs = []\n",
    "sample_fits = {}\n",
    "all_fits = {}\n",
    "\n",
    "for i, sample in tqdm(enumerate(sorted(samples))):\n",
    "    \n",
    "    subplot(num_rows, num_columns, i+1)\n",
    "    \n",
    "    rna_sample = sample[0]\n",
    "    nucleotide = sample[1]\n",
    "\n",
    "    #extracting the df for that sample, nucleotide combo\n",
    "    working_df = flex_map_df[(flex_map_df['Sample']==rna_sample) & (flex_map_df['Nucleotide']==nucleotide)]\n",
    "    \n",
    "    #times are time points (t), fraction intact values (fi)\n",
    "    #to be used in fi = np.exp(-b*t) fit for b coefficient --> kdeg calculation\n",
    "    times = np.array(working_df['Timepoint'])[:8]\n",
    "    frac_intact = np.array(working_df['fraction_intact'])[:8]\n",
    "\n",
    "    scatter(times, frac_intact, label='Data', s=20, marker='o')\n",
    "    \n",
    "    fit_dict = {}\n",
    "    try:\n",
    "        print('Trying an exponential fit...'+str(sample))\n",
    "        fits = np.array(log_transform_fit(timepoints = times, frac_intact=frac_intact, bs_iter=1000))\n",
    "        kdeg = np.average(fits)\n",
    "        kdeg_err = np.std(fits)\n",
    "        print('kdeg: '+str(kdeg))\n",
    "        print('kdeg_err: '+str(kdeg_err))\n",
    "        fit_dict['kdeg'] = kdeg\n",
    "        fit_dict['kdeg_err'] = kdeg_err\n",
    "        \n",
    "#         plotting fit\n",
    "        plot(np.arange(0,24,0.05), frac_intact[0]*np.exp(-1*kdeg*np.arange(0,24,0.05)), linewidth=3, label='Fit')\n",
    "        \n",
    "    except RuntimeError:\n",
    "        print('Could not converge for...'+str(sample))\n",
    "        fit_dict['kdeg'] = 'Error'\n",
    "        fit_dict['kdeg_err'] = 'Error'\n",
    "        continue\n",
    "    \n",
    "    sample_fits[sample] = fit_dict\n",
    "    all_fits[sample] = fits\n",
    "    \n",
    "    legend(loc='upper left', bbox_to_anchor=(1.05,1), fontsize=14)\n",
    "    title('{}'.format(rna_sample), fontsize=12)\n",
    "    xlabel('Time (hours)')\n",
    "    ylabel('Fraction Intact')\n",
    "    tight_layout()\n",
    "\n",
    "savefig(plot_dir+'flex_peaks_4tps_numpy_exponential_fit.pdf')\n",
    "#     clf()\n",
    "\n",
    "pd.DataFrame.from_dict(sample_fits, orient='index').to_csv('12-10_flex_peaks_4tps_expfits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fits_df = pd.DataFrame.from_dict(all_fits, orient='index')\n",
    "all_fits_df = all_fits_df.reset_index().rename({'index':'Sample'})\n",
    "all_fits_df_long = pd.melt(all_fits_df, id_vars=['index'], value_vars=np.arange(1000))\n",
    "all_fits_df_long['Sample'] = [str(sample[0]) for sample in all_fits_df_long['index']]\n",
    "all_fits_df_long['Nucleotide'] = [str(sample[1]) for sample in all_fits_df_long['index']]\n",
    "all_fits_df_long['kdeg'] = [float(x) for x in all_fits_df_long['value']]\n",
    "\n",
    "kdeg_df_long = all_fits_df_long[['Sample', 'Nucleotide', 'kdeg']]\n",
    "\n",
    "\n",
    "figure(figsize=(10,6))\n",
    "sns.barplot(data=kdeg_df_long, x='Sample', y='kdeg', hue='Nucleotide', ci='sd', palette='cividis')\n",
    "xlabel('RNA')\n",
    "ylabel('kdeg (hr-1)')\n",
    "legend(title='Nucleotide Type',loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=14)\n",
    "xticks(ha='right', rotation=45)\n",
    "tight_layout()\n",
    "savefig(plot_dir+'kdeg_fits.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kdeg_df_long\n",
    "\n",
    "seqid_names = pd.read_csv('seqid_names.csv')\n",
    "seqid_names_dict = dict(zip(seqid_names['Human readable name'], seqid_names['Barcode']))\n",
    "# seqid_names_dict\n",
    "\n",
    "seqid_list = []\n",
    "for row in kdeg_df_long.itertuples():\n",
    "    seqid_list.append(seqid_names_dict[row.Sample])\n",
    "    \n",
    "kdeg_df_long['seqid'] = seqid_list\n",
    "\n",
    "# kdeg_df_long\n",
    "\n",
    "figure(figsize=(10,6))\n",
    "sns.barplot(data=kdeg_df_long.sort_values(by='seqid', ascending=True), x='Sample', y='kdeg', hue='Nucleotide', ci='sd', palette='cividis')\n",
    "xlabel('RNA')\n",
    "ylabel('kdeg (hr-1)')\n",
    "ylim(0,1)\n",
    "legend(title='Nucleotide Type',loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=14)\n",
    "xticks(ha='right', rotation=45)\n",
    "tight_layout()\n",
    "savefig(plot_dir+'kdeg_fits_ordered_seqid.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits_df = pd.DataFrame(sample_fits).T\n",
    "# fits_df = fits_df.reset_index()\n",
    "\n",
    "# fits_df.rename({'level_0': 'Sample', 'level_1': 'Nucleotide'})\n",
    "\n",
    "# sns.barplot(data=fits_df, y='kdeg', x='level_0', hue='level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}